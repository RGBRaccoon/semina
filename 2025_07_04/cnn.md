# CNN : Convolution Neural Network
# https://www.kaggle.com/datasets/tongpython/cat-and-dog?select=test_set
목차
1. CNN이란
2. CNN의 핵심 구성 요소
3. CNN의 동작 원리
4. 주요 CNN 아키텍처
5. 최신 CNN 기반 모델델
6. 코드
7. 전망? 어디에 쓸 수 있을것이다?



1. CNN이란
CNN = Convolution Neural Network
이건 주로 어디에 쓰이는가? 이미지, 비디오와 같은 시각적 데이터를 분석하는 데 사용되는 딥러닝 알고리즘

Convolution : 합성곱
합성곱이란?
합성곱은 신호처리 분야에서 사용되는 용어로, 이미지 프로세싱에서 일정한 패턴으로 변환하기 위해 수행하는 행렬연산입니다. 
수학적으로는 하나의 함수와 또 다른 함수를 반전 이동한 값을 곱한 다음, 구간에 대해 적분하여 새로운 함수를 구하는 연산자입니다
1. 기존 방식: 완전 연결 신경망 (Fully Connected Neural Network, FCNN) 또는 다층 퍼셉트론 (Multi-Layer Perceptron, MLP)

구조: 이 방식은 각 계층의 모든 뉴런이 다음 계층의 모든 뉴런과 완전히 연결되어 있는 형태입니다. 이미지 데이터를 입력으로 받을 때, 이미지를 1차원 벡터로 '평탄화'하여 입력 계층에 넣습니다.

작동 방식: 모든 픽셀 값을 독립적인 입력 특징으로 간주하고, 각 픽셀 값과 다음 계층 뉴런 사이의 모든 가능한 연결에 대해 가중치를 학습합니다.

기존 방식의 문제점:

막대한 파라미터(가중치) 수:

예시: 100×100 크기의 컬러 이미지(3채널)는 100×100×3=30,000개의 픽셀 값을 가집니다. 만약 이 이미지를 입력으로 받아 다음 계층에 1,000개의 뉴런이 있다면, 30,000×1,000=3천만개의 가중치가 필요합니다. 이는 모델의 크기를 비정상적으로 키워 계산 비용을 증가시키고 학습을 매우 어렵게 만듭니다.

문제점의 본질: 이미지의 공간적 구조(어떤 픽셀이 옆에 있는지 등)를 무시하고 모든 픽셀을 개별적인 독립적인 입력으로 취급하기 때문에 비효율성이 발생합니다.

공간적 정보 손실:

이미지를 1차원 벡터로 평탄화하는 과정에서 픽셀들의 2D 또는 3D 공간적 배열 정보(어떤 픽셀이 서로 이웃하는지 등)가 완전히 사라집니다. 예를 들어, 눈, 코, 입의 상대적인 위치와 같은 중요한 시각적 패턴을 학습하기 어렵게 만듭니다.

번역 불변성(Translation Invariance) 부족:

만약 모델이 이미지의 특정 위치(예: 왼쪽 상단)에서 고양이의 특징을 학습했다면, 고양이가 다른 위치(예: 오른쪽 하단)로 이동하면 이를 새로운 특징으로 간주하고 다시 학습해야 할 수 있습니다. 이는 모델의 일반화 능력을 떨어뜨립니다.

과적합(Overfitting) 위험:

파라미터 수가 너무 많으면 모델이 훈련 데이터에 과도하게 맞춰져 실제 새로운 데이터에서는 성능이 떨어지는 과적합 문제가 쉽게 발생합니다.

2. 컨볼루션(Convolution)의 구조 및 문제 해결 방식

컨볼루션은 위에서 언급된 FCNN의 문제점들을 효과적으로 해결하기 위해 고안된 구조입니다.

컨볼루션의 핵심 구조 (재강조):

필터/커널 (Filter/Kernel): 이미지 내의 특정 특징(선, 모서리, 질감 등)을 감지하는 작은 행렬입니다. 마치 돋보기와 같습니다.

스트라이드 (Stride): 필터가 이미지를 스캔할 때 한 번에 움직이는 보폭입니다. (예: 1픽셀씩 이동, 2픽셀씩 이동)

패딩 (Padding): 이미지의 가장자리를 0으로 채워 넣어 컨볼루션 연산 후에도 이미지의 공간적 크기를 유지하거나 특정 필터 크기에 맞추는 기술입니다.

특징 맵 (Feature Map): 컨볼루션 연산의 결과물로, 필터가 원본 이미지에서 감지한 특징들이 강조되어 나타나는 새로운 이미지입니다.

컨볼루션이 기존 문제를 해결하는 방식:

파라미터 수의 획기적 감소 (가중치 공유 - Weight Sharing):

FCNN은 각 입력 픽셀과 다음 계층 뉴런 간에 개별적인 가중치를 가집니다.

컨볼루션은 **하나의 필터(예: 3×3 필터는 9개의 가중치)**가 이미지 전체를 스캔하며 사용됩니다. 즉, 이 9개의 가중치가 이미지의 모든 위치에서 공유됩니다.

해결: 이미지 전체에 대해 소수의 필터 가중치만 학습하면 되므로, 모델이 학습해야 할 총 파라미터 수가 극적으로 줄어들어 계산 효율성이 비약적으로 증가하고 과적합 위험이 감소합니다.

공간적 정보 보존 및 지역적 특징 추출 (지역 수용장 - Local Receptive Fields):

FCNN은 이미지를 1차원으로 평탄화하여 공간 정보를 잃습니다.

컨볼루션은 필터가 이미지의 **제한된 지역(Local Receptive Field)**에만 집중하여 연산을 수행합니다. 이웃하는 픽셀들 간의 관계를 직접적으로 학습하여 이미지의 선, 모서리, 텍스처 등 지역적인 패턴을 효과적으로 추출합니다.

해결: 이미지의 공간적 구조를 유지하면서 유의미한 특징들을 계층적으로 추출할 수 있게 됩니다. 초기 계층에서는 간단한 특징, 후기 계층에서는 복합적인 특징을 학습합니다.

번역 불변성(Translation Invariance) 확보:

FCNN은 특징의 위치 변화에 취약합니다.

컨볼루션은 동일한 필터가 이미지의 모든 위치에서 특정 특징을 감지할 수 있도록 합니다.

해결: 이미지 내에서 특징의 위치가 약간 바뀌더라도, 동일한 필터가 이를 인식할 수 있는 능력을 부여하여 모델의 일반화 능력을 향상시킵니다.

3. 추가적인 컨볼루션의 특징 (CNN의 구성 요소)

컨볼루션 신경망(CNN)은 단순히 컨볼루션 계층만으로 이루어져 있지 않습니다. 컨볼루션 계층과 함께 작동하여 성능을 극대화하는 추가적인 특징들이 있습니다.

풀링 계층 (Pooling Layer):

목적: 특징 맵의 크기를 줄이고(다운샘플링), 가장 중요한 특징만 남겨 노이즈를 줄이며, 약간의 위치 변화에도 강건하도록 만듭니다.

종류: 최대 풀링(Max Pooling, 특정 영역에서 가장 큰 값만 남김), 평균 풀링(Average Pooling, 평균값 남김) 등이 있습니다.

효과: 모델의 계산 부담을 줄이고, 과적합을 방지하며, 특징의 미세한 위치 변화에 대한 불변성을 강화합니다.

활성화 함수 (Activation Function):

목적: 신경망에 비선형성을 도입하여 복잡한 패턴을 학습할 수 있게 합니다. (예: ReLU, Sigmoid, Tanh)

컨볼루션 연산 결과에 적용되어 다음 계층으로 전달될 값을 결정합니다.

다수의 컨볼루션 계층 및 풀링 계층:

CNN은 여러 개의 컨볼루션 계층과 풀링 계층을 쌓아 올리는 것이 일반적입니다. 이를 통해 모델은 이미지의 저수준 특징(예: 모서리, 선)부터 고수준 특징(예: 눈, 코, 얼굴 전체)까지 점진적이고 계층적으로 학습할 수 있습니다.

완전 연결 계층 (Fully Connected Layer):

최종적으로 추출된 고수준 특징들을 기반으로 분류(Classification)나 회귀(Regression)와 같은 최종 결정을 내리기 위해 CNN의 마지막 부분에는 FCNN과 유사한 완전 연결 계층이 사용됩니다.

2. CNN의 핵심 구성 요소 / CNN의 동작 원리 (아직 부족)

그래서 CNN은 어떻게 해결을 했는가!
CNN은 어떻게 생겨먹어서 어떻게 움직이길래 문제를 해결 할 수 있었는가?

2.1 CNN의 전체 구조
CNN은 크게 특징 추출 부분(Convolutional Layer/Pooling Layer)과 클래스를 분류하는 부분(Fully-Connected Layer)으로 나뉩니다.

2.2 합성곱층(Convolutional Layer)
합성곱층은 CNN의 가장 핵심적인 구성 요소입니다. 이 층에서는 **필터(Filter) 또는 커널(Kernel)**이라고 불리는 작은 행렬을 사용하여 입력 이미지에서 특징을 추출합니다.

합성곱 연산 과정
필터 적용: 필터가 입력 이미지를 처음부터 끝까지 슬라이딩합니다

요소별 곱셈: 필터와 겹치는 부분의 각 픽셀값을 곱하고 모두 더합니다

특징 맵 생성: 합성곱 연산의 결과로 Feature Map이 생성됩니다

중요한 하이퍼파라미터
Stride: 필터의 이동 간격을 조절합니다

Padding: 입력 이미지의 가장자리에 0을 추가하여 출력 크기를 조절합니다

2.3 풀링층(Pooling Layer)
풀링층은 합성곱층에서 나온 특징 맵의 크기를 줄이는 역할을 합니다. 주요 목적은 다음과 같습니다:

차원성 감소: 계산 비용을 줄이고 과적합을 제어합니다

변환 불변성: 입력의 작은 변화에도 안정적인 출력을 제공합니다

중요 특징 선택: 가장 중요한 특징만 유지합니다

풀링 방법
Max Pooling: 지정된 영역에서 최대값만 추출

Average Pooling: 지정된 영역의 평균값을 추출

2.4 활성화 함수와 완전연결층
합성곱 연산 후에는 ReLU(Rectified Linear Unit) 같은 활성화 함수를 적용하여 비선형성을 도입합니다. CNN의 마지막 부분에는 완전연결층이 위치하여 앞서 추출된 특징들을 바탕으로 최종 분류를 수행합니다.


4. 주요 CNN 아키텍처
가장 유명한 CNN을 2개정도? 그리고 이건 어디 쓰이는가?
5. 최신 CNN 기반 모델
최신 CNN 사용 모델소개. + conformer를 중간에 끼우기.
Conformer: CNN-Transformer 융합의 대표 모델
Conformer는 Convolution-augmented Transformer로, 음성 인식을 위해 개발된 모델입니다. Conformer는 다음과 같은 특징을 가집니다:

지역적 특징과 전역적 특징 결합: CNN은 지역적 특징을 효과적으로 추출하고, Transformer는 전역적 상호작용을 잘 포착합니다

매개변수 효율성: 오디오 시퀀스의 local 및 global 의존성을 효율적으로 모델링합니다

뛰어난 성능: LibriSpeech 벤치마크에서 언어 모델 없이 2.1%/4.3%의 WER을 달성했습니다

CMT (Convolutional Neural Networks Meet Vision Transformers)
CMT는 CNN과 Vision Transformer의 하이브리드 모델입니다:

4-stage 구조: 최신 CNN 모델처럼 4-stage로 구성되어 있습니다

다중 스케일 특징 추출: Stage별로 해상도를 줄이고 Feature Dimension을 증가시킵니다

효율적인 연산: 적은 연산량으로도 우수한 일반화 성능을 보입니다

6. 코드
가장 간단한 CNN 모델을 사용해서 간단하게 돌린거 하나

최신 모델을 이용해서 돌린거 하나씩.

7. 전망? 어디에 쓸 수 있을것이다?
CNN과 Transformer의 융합이 더욱 활발해져 각각의 장점을 극대화한 모델들이 등장하고 있습니다. 이는 더욱 정확하고 효율적인 이미지 처리를 가능하게 합니다.
Conformer나 CNT 같은 거는 전부 트랜스포머와의 하이브리드인데, 특징이 뭐지?
산업 자동화: 생산 라인의 불량품 검사, 로봇 팔의 정밀 제어, 재고 관리 등 스마트 팩토리 구현에 필수적인 시각 인공지능 기술로 자리매김할 것입니다.???
우리는 이 모델로 ~~한걸 할 수 잇을거같다.