{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # 고양이 이미지 (label: 0)\n",
    "        cat_dir = os.path.join(root_dir, 'cats')\n",
    "        if os.path.exists(cat_dir):\n",
    "            for img_name in os.listdir(cat_dir):\n",
    "                if img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    self.images.append(os.path.join(cat_dir, img_name))\n",
    "                    self.labels.append(0)\n",
    "        \n",
    "        # 개 이미지 (label: 1)\n",
    "        dog_dir = os.path.join(root_dir, 'dogs')\n",
    "        if os.path.exists(dog_dir):\n",
    "            for img_name in os.listdir(dog_dir):\n",
    "                if img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    self.images.append(os.path.join(dog_dir, img_name))\n",
    "                    self.labels.append(1)\n",
    "        \n",
    "        print(f\"Loaded {len(self.images)} images\")\n",
    "        print(f\"Cats: {self.labels.count(0)}, Dogs: {self.labels.count(1)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # 이미지 로드 및 전처리\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_classes):\n",
    "        super(FCNN, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        # 은닉층들\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.3))  # 과적합 방지\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # 출력층\n",
    "        layers.append(nn.Linear(prev_size, num_classes))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 입력을 1차원으로 평탄화 (FCNN의 핵심 특징)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # 학습 모드\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            train_total += target.size(0)\n",
    "            train_correct += (predicted == target).sum().item()\n",
    "            \n",
    "            if batch_idx % 50 == 0:\n",
    "                print(f'Epoch: {epoch+1}/{num_epochs}, Batch: {batch_idx}/{len(train_loader)}, '\n",
    "                      f'Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # 검증 모드\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                val_total += target.size(0)\n",
    "                val_correct += (predicted == target).sum().item()\n",
    "        \n",
    "        # 평균 손실과 정확도 계산\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        train_accuracy = 100 * train_correct / train_total\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}%')\n",
    "        print(f'  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
    "        print('-' * 50)\n",
    "    \n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    report = classification_report(all_targets, all_predictions, \n",
    "                                 target_names=['Cat', 'Dog'])\n",
    "    \n",
    "    return accuracy, report\n",
    "\n",
    "def plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # 손실 그래프\n",
    "    ax1.plot(train_losses, label='Train Loss')\n",
    "    ax1.plot(val_losses, label='Validation Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # 정확도 그래프\n",
    "    ax2.plot(train_accuracies, label='Train Accuracy')\n",
    "    ax2.plot(val_accuracies, label='Validation Accuracy')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fcnn_training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/archive/training_set/training_set'\n",
    "test_dir = 'data/archive/test_set/test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64  # 64x64로 설정하여 계산량 줄이기\n",
    "    \n",
    "    # 데이터 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 데이터셋 로드\n",
    "print(\"Loading datasets...\")\n",
    "train_dataset = CatDogDataset(train_dir, transform=transform)\n",
    "test_dataset = CatDogDataset(test_dir, transform=transform)\n",
    "\n",
    "# 데이터 로더 생성\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                        shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, \n",
    "                       shuffle=False, num_workers=2)\n",
    "\n",
    "# FCNN 모델 생성\n",
    "input_size = img_size * img_size * 3  # RGB 3채널\n",
    "hidden_sizes = [512, 256, 128]  # 은닉층 크기\n",
    "num_classes = 2  # 고양이, 개\n",
    "\n",
    "print(f\"Input size: {input_size}\")\n",
    "print(f\"Hidden sizes: {hidden_sizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCNN(input_size, hidden_sizes, num_classes).to(device)\n",
    "    \n",
    "# 모델 정보 출력\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# 손실 함수와 옵티마이저\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 시작\n",
    "print(\"\\nStarting FCNN training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = train_model(\n",
    "    model, train_loader, test_loader, criterion, optimizer, num_epochs=10\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# 모델 평가\n",
    "print(\"\\nEvaluating model...\")\n",
    "test_accuracy, test_report = evaluate_model(model, test_loader)\n",
    "\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(test_report)\n",
    "\n",
    "# 학습 과정 시각화\n",
    "plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "\n",
    "# 모델 저장\n",
    "torch.save(model.state_dict(), 'fcnn_cat_dog_model.pth')\n",
    "print(\"\\nModel saved as 'fcnn_cat_dog_model.pth'\")\n",
    "\n",
    "# FCNN의 특징 요약\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FCNN 모델 특징 요약:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"1. 입력 크기: {img_size}x{img_size}x3 = {input_size} (평탄화됨)\")\n",
    "print(f\"2. 총 매개변수: {total_params:,}\")\n",
    "print(f\"3. 은닉층 구조: {hidden_sizes}\")\n",
    "print(f\"4. 최종 테스트 정확도: {test_accuracy:.4f}\")\n",
    "print(f\"5. 학습 시간: {training_time:.2f}초\")\n",
    "print(\"\\nFCNN의 한계점:\")\n",
    "print(\"- 공간적 정보 손실 (이미지가 1차원으로 평탄화됨)\")\n",
    "print(\"- 많은 매개변수로 인한 과적합 위험\")\n",
    "print(\"- 위치 변화에 민감함\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
